{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OmarMohy/LangChain-Playground/blob/main/LAB_2_Calculator_App.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculator Agent\n",
        "\n",
        "This Calculator agent has the following tools:\n",
        "\n",
        "- **Tool 1: Parsing the equation:** It takes a math problem and it extracts the corresponding equation (e.g., '5+2') using an LLM.\n",
        "- **Tool 2: Performing the operation:** It takes an equation and uses the calculator API to solve it (e.g., '5+2=7').\n",
        "- **Tool 3: Generating the answer:** It takes the math problem and the solved equation, and it uses an LLM to formulate an solution to the problem.\n"
      ],
      "metadata": {
        "id": "x83zscDAm7WY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installations\n",
        "\n",
        "To get started, we first need to set up our environment by installing the necessary libraries. This step ensures that we have all the dependencies required to build our calculator agent. We'll be using LangChain as our primary framework, which provides the tools and components needed to create and connect our agent's different functionalities. We'll also install the langchain-google-genai library to leverage a powerful Google model, like gemini-1.5-flash, as the agent's core engine."
      ],
      "metadata": {
        "id": "JeLm9tcVm943"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain langchain-google-genai google-generativeai langgraph wikipedia langchain_community\n",
        "\n",
        "print(\"Libraries installed: langchain, langchain-google-genai, google-generativeai, langgraph, wikipedia, langchain_community\")\n",
        "print(\"Libraries installed: langchain, langchain-google-genai, google-generativeai, langgraph, wikipedia\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4uQdib3-3nK",
        "outputId": "4a0fdd10-77ef-4ca5-d082-ad3cb92a004a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.3/53.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m713.3/713.3 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.9/234.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires google-auth==2.43.0, but you have google-auth 2.47.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mLibraries installed: langchain, langchain-google-genai, google-generativeai, langgraph, wikipedia, langchain_community\n",
            "Libraries installed: langchain, langchain-google-genai, google-generativeai, langgraph, wikipedia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage\n",
        "import time # For slight delays to help with rate limits\n",
        "\n",
        "# Retrieve the API key from Colab secrets\n",
        "try:\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "    os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY\n",
        "    print(\"Google API Key loaded from Colab secrets!\")\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"Error: GOOGLE_API_KEY not found in Colab secrets.\")\n",
        "    print(\"Please ensure you have set a secret named 'GOOGLE_API_KEY' in Colab.\")\n",
        "    print(\"You can get a free key from https://aistudio.google.com/.\")\n",
        "    raise ValueError(\"API Key not configured. Please set GOOGLE_API_KEY in Colab secrets.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred while loading API Key: {e}\")\n",
        "    raise\n",
        "\n",
        "# Initialize a base LLM that all our agents will use as their \"brain\"\n",
        "# We'll stick to gemini-1.5-flash for its speed and free tier.\n",
        "base_llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.1, convert_system_message_to_human=True)\n",
        "\n",
        "print(f\"Base LLM initialized: {base_llm.model}\")\n",
        "print(\"This base LLM will power our specialized agents for understanding and generating text.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "SMymU75s-4kZ",
        "outputId": "44978e01-2e74-45d8-97fe-4cfd1fa65347"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain.prompts'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-62617616.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_google_genai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatGoogleGenerativeAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatPromptTemplate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseMessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHumanMessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAIMessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mToolMessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;31m# For slight delays to help with rate limits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain.prompts'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage\n",
        "import time # For slight delays to help with rate limits\n",
        "\n",
        "# Retrieve the API key from Colab secrets\n",
        "try:\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "    os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY\n",
        "    print(\"Google API Key loaded from Colab secrets!\")\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"Error: GOOGLE_API_KEY not found in Colab secrets.\")\n",
        "    print(\"Please ensure you have set a secret named 'GOOGLE_API_KEY' in Colab.\")\n",
        "    print(\"You can get a free key from https://aistudio.google.com/.\")\n",
        "    raise ValueError(\"API Key not configured. Please set GOOGLE_API_KEY in Colab secrets.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred while loading API Key: {e}\")\n",
        "    raise\n",
        "\n",
        "# Initialize a base LLM that all our agents will use as their \"brain\"\n",
        "# We'll stick to gemini-1.5-flash for its speed and free tier.\n",
        "base_llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.1, convert_system_message_to_human=True)\n",
        "\n",
        "print(f\"Base LLM initialized: {base_llm.model}\")\n",
        "print(\"This base LLM will power our specialized agents for understanding and generating text.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99d9010f-51e0-47c0-bcc5-f07c8278b700",
        "id": "zwihG6uI1HkC"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google API Key loaded from Colab secrets!\n",
            "Base LLM initialized: gemini-1.5-flash\n",
            "This base LLM will power our specialized agents for understanding and generating text.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "# Filter out the specific UserWarning from langchain_google_genai\n",
        "warnings.filterwarnings(\"ignore\", message=\"Convert_system_message_to_human will be deprecated!\", module=\"langchain_google_genai\")\n",
        "\n",
        "print(\"Warning for 'Convert_system_message_to_human will be deprecated!' is now suppressed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uvwetXlf04B",
        "outputId": "1f4f58c4-d21c-4264-a512-f059fd378609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning for 'Convert_system_message_to_human will be deprecated!' is now suppressed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tool 1: Parsing the equation from the math problem\n",
        "\n",
        "The first challenge in building a calculator agent is to translate a user's natural language question into a formal mathematical expression that a computer can understand. In this section, we use a LangChain prompt template to guide our Large Language Model (LLM) to extract the equation. The prompt is carefully designed to ask the LLM to identify the core mathematical operation(s) and numbers from the user's query, transforming a sentence like \"What is 10 plus 5?\" into a simple equation like \"10 + 5\"."
      ],
      "metadata": {
        "id": "9O24LWJmnVQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_equation_from_word_problem(word_problem: str) -> str:\n",
        "    \"\"\"\n",
        "    Uses an LLM to extract the mathematical equation from a word problem.\n",
        "\n",
        "    Args:\n",
        "        word_problem: The math word problem as a string.\n",
        "\n",
        "    Returns:\n",
        "        A string representing the extracted mathematical equation, ready for a calculator.\n",
        "    \"\"\"\n",
        "    # Define the prompt for the LLM\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"Extract the mathematical equation from the word problem. Provide ONLY the equation itself, in a format suitable for direct input into a calculator or mathematical solver. For example, if the problem is 'What is 5 plus 3?', output '5 + 3'.\"),\n",
        "        (\"user\", \"Extract the equation from the following word problem: {word_problem}\")\n",
        "    ])\n",
        "\n",
        "    # Chain the prompt and the LLM\n",
        "    chain = prompt | base_llm\n",
        "\n",
        "    # Invoke the chain with the word problem\n",
        "    response = chain.invoke({\"word_problem\": word_problem})\n",
        "\n",
        "    # Return the extracted equation, ensuring no leading/trailing whitespace\n",
        "    return response.content.strip()\n",
        "\n",
        "# Example usage:\n",
        "word_problem = \"I have three apples and ate 1, how many do I have\"\n",
        "equation = get_equation_from_word_problem(word_problem)\n",
        "print(f\"Word Problem: {word_problem}\")\n",
        "print(f\"Extracted Equation: {equation}\")\n",
        "\n",
        "word_problem_2 = \"If a car travels at 60 miles per hour for 2 hours, how far does it travel?\"\n",
        "equation_2 = get_equation_from_word_problem(word_problem_2)\n",
        "print(f\"Word Problem: {word_problem_2}\")\n",
        "print(f\"Extracted Equation: {equation_2}\")\n",
        "\n",
        "word_problem_3 = \"What is the sum of 10 and 25 divided by 5?\"\n",
        "equation_3 = get_equation_from_word_problem(word_problem_3)\n",
        "print(f\"Word Problem: {word_problem_3}\")\n",
        "print(f\"Extracted Equation: {equation_3}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smmB9VKqC2yo",
        "outputId": "feeb545c-161c-43d3-8d11-e746bb26eb4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Problem: I have three apples and ate 1, how many do I have\n",
            "Extracted Equation: 3 - 1\n",
            "Word Problem: If a car travels at 60 miles per hour for 2 hours, how far does it travel?\n",
            "Extracted Equation: 60 * 2\n",
            "Word Problem: What is the sum of 10 and 25 divided by 5?\n",
            "Extracted Equation: (10 + 25) / 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tool 2: Performing the mathematical operation\n",
        "\n",
        "Once we have extracted the equation, we need a way to perform the calculation. An LLM on its own isn't reliable for precise mathematical operations. This is where tools come in. In this section, we'll create a dedicated Python tool to perform the calculation accurately. This tool, which we can call calculate_equation, takes the extracted equation as input and uses Python's built-in functionality to compute the result. This separates the creative task of parsing the user's request from the analytical task of solving the math problem."
      ],
      "metadata": {
        "id": "KAnMV9OsoOiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math # Import math for more complex operations if needed\n",
        "\n",
        "def calculate_equation(equation: str) -> float:\n",
        "    \"\"\"\n",
        "    Evaluates a mathematical equation string and returns the numerical result.\n",
        "\n",
        "    Args:\n",
        "        equation: The mathematical equation as a string (e.g., '4*2-3').\n",
        "\n",
        "    Returns:\n",
        "        The numerical result of the equation.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # WARNING: Using eval() can be dangerous if the input is not trusted.\n",
        "        # In a real application, you would use a secure math expression parser or a dedicated calculator API.\n",
        "        # Provide access to math functions within eval's scope\n",
        "        result = eval(equation, {\"__builtins__\": None}, {\"math\": math, \"sqrt\": math.sqrt, \"log\": math.log})\n",
        "        return float(result)\n",
        "    except Exception as e:\n",
        "        print(f\"Error evaluating equation '{equation}': {e}\")\n",
        "        return float('nan') # Return NaN for invalid equations\n",
        "\n",
        "# Example usage:\n",
        "equation_to_calculate = \"3 - 1\"\n",
        "result = calculate_equation(equation_to_calculate)\n",
        "print(f\"Equation: {equation_to_calculate}\")\n",
        "print(f\"Result: {result}\")\n",
        "\n",
        "equation_to_calculate_2 = \"60 * 2\"\n",
        "result_2 = calculate_equation(equation_to_calculate_2)\n",
        "print(f\"Equation: {equation_to_calculate_2}\")\n",
        "print(f\"Result: {result_2}\")\n",
        "\n",
        "equation_to_calculate_3 = \"(10 + 25) / 5\"\n",
        "result_3 = calculate_equation(equation_to_calculate_3)\n",
        "print(f\"Equation: {equation_to_calculate_3}\")\n",
        "print(f\"Result: {result_3}\")\n",
        "\n",
        "equation_to_calculate_4 = \"sqrt(16) + log(10)\" # Example with math functions\n",
        "result_4 = calculate_equation(equation_to_calculate_4)\n",
        "print(f\"Equation: {equation_to_calculate_4}\")\n",
        "print(f\"Result: {result_4}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0sDpjAgdw63",
        "outputId": "5e61fb9e-7bea-4978-c17a-ee7643641eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Equation: 3 - 1\n",
            "Result: 2.0\n",
            "Equation: 60 * 2\n",
            "Result: 120.0\n",
            "Equation: (10 + 25) / 5\n",
            "Result: 7.0\n",
            "Equation: sqrt(16) + log(10)\n",
            "Result: 6.302585092994046\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tool 3: Generating an answer\n",
        "\n",
        "The final step is to combine the calculated result with the original query to formulate a human-friendly answer. We use another LangChain prompt template for this. The prompt takes the user's original question and the numerical result from our calculator tool and instructs the LLM to generate a complete sentence. For example, it will turn a result of 25 and the original question \"What is 5 times 5?\" into the final answer, \"5 times 5 is 25.\""
      ],
      "metadata": {
        "id": "rR6ztscIp0am"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5388785d",
        "outputId": "741f5dce-681f-4fcf-bde4-4c1dd8917e3b"
      },
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "def generate_answer_sentence(word_problem: str, equation: str, result: float) -> str:\n",
        "    \"\"\"\n",
        "    Uses an LLM to generate a natural language sentence answering the word problem,\n",
        "    given the original problem, the extracted equation, and the calculated result.\n",
        "\n",
        "    Args:\n",
        "        word_problem: The original math word problem.\n",
        "        equation: The extracted mathematical equation.\n",
        "        result: The numerical result of the equation.\n",
        "\n",
        "    Returns:\n",
        "        A string containing a natural language answer to the word problem.\n",
        "    \"\"\"\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"You are a helpful assistant that provides the answer to a math word problem in a clear and concise sentence. Given the original problem, the equation used, and the result, formulate a sentence that answers the original question.\"),\n",
        "        (\"user\", \"Word Problem: {word_problem}\\nEquation: {equation}\\nResult: {result}\\n\\nProvide the answer in a sentence.\")\n",
        "    ])\n",
        "\n",
        "    chain = prompt | base_llm\n",
        "\n",
        "    response = chain.invoke({\"word_problem\": word_problem, \"equation\": equation, \"result\": result})\n",
        "\n",
        "    return response.content.strip()\n",
        "\n",
        "# Example usage (assuming you have called the previous functions to get equation and result):\n",
        "word_problem_example = \"I have three apples and ate 1, how many do I have\"\n",
        "equation_example = \"3 - 1\" # This would come from get_equation_from_word_problem\n",
        "result_example = 2.0 # This would come from calculate_equation\n",
        "\n",
        "answer_sentence = generate_answer_sentence(word_problem_example, equation_example, result_example)\n",
        "print(f\"Word Problem: {word_problem_example}\")\n",
        "print(f\"Answer: {answer_sentence}\")\n",
        "\n",
        "word_problem_example_2 = \"If a car travels at 60 miles per hour for 2 hours, how far does it travel?\"\n",
        "equation_example_2 = \"60 * 2\"\n",
        "result_example_2 = 120.0\n",
        "\n",
        "answer_sentence_2 = generate_answer_sentence(word_problem_example_2, equation_example_2, result_example_2)\n",
        "print(f\"Word Problem: {word_problem_example_2}\")\n",
        "print(f\"Answer: {answer_sentence_2}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Problem: I have three apples and ate 1, how many do I have\n",
            "Answer: You have 2 apples left.\n",
            "Word Problem: If a car travels at 60 miles per hour for 2 hours, how far does it travel?\n",
            "Answer: The car travels 120 miles.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_problem = \"I have ten apples and ate one of them, how many do I have\"\n",
        "print(f\"Word Problem: {word_problem}\")\n",
        "equation = get_equation_from_word_problem(word_problem)\n",
        "print(f\"Extracted Equation: {equation}\")\n",
        "result_from_equation = calculate_equation(equation)\n",
        "print(f\"Calculated Result from Equation: {result_from_equation}\")\n",
        "answer_sentence = generate_answer_sentence(word_problem, equation, result_from_equation)\n",
        "print(f\"Answer Sentence: {answer_sentence}\")"
      ],
      "metadata": {
        "id": "FmVXKG7Af6JH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fa90828-8d1b-4b78-fbab-bab1cdb76a43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Problem: I have ten apples and ate one of them, how many do I have\n",
            "Extracted Equation: 10 - 1\n",
            "Calculated Result from Equation: 9.0\n",
            "Answer Sentence: You have 9 apples left.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Whole agentic workflow\n",
        "\n",
        "This section brings everything together. We'll use LangChain Expression Language (LCEL) to connect the different components we’ve built—the prompt to extract the equation, the LLM, and the calculator tool. We’ll chain these elements together into a single, seamless workflow. This chain represents our complete agent, which can now take a user query, parse it, perform a calculation, and generate a final response in one fluid motion."
      ],
      "metadata": {
        "id": "ZEy4I7ROrMeO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d100d48",
        "outputId": "de2e0be5-f7e4-4752-c058-0dfdd9a8f85e"
      },
      "source": [
        "def solve_word_problem(word_problem: str) -> str:\n",
        "    \"\"\"\n",
        "    Solves a math word problem by extracting the equation, calculating the result,\n",
        "    and generating a natural language answer sentence.\n",
        "\n",
        "    Args:\n",
        "        word_problem: The math word problem as a string.\n",
        "\n",
        "    Returns:\n",
        "        A string containing the natural language answer to the word problem,\n",
        "        or an error message if the problem could not be solved.\n",
        "    \"\"\"\n",
        "    # 1. Extract the equation\n",
        "    equation = get_equation_from_word_problem(word_problem)\n",
        "    print(f\"Extracted Equation: {equation}\")\n",
        "\n",
        "    if not equation:\n",
        "        return \"Could not extract a valid equation from the word problem.\"\n",
        "\n",
        "    # 2. Calculate the result\n",
        "    result = calculate_equation(equation)\n",
        "    print(f\"Calculated Result: {result}\")\n",
        "\n",
        "    if math.isnan(result):\n",
        "        return f\"Could not calculate the result for the equation: {equation}\"\n",
        "\n",
        "    # 3. Generate the answer sentence\n",
        "    answer_sentence = generate_answer_sentence(word_problem, equation, result)\n",
        "\n",
        "    return answer_sentence\n",
        "\n",
        "# Example usage:\n",
        "word_problem_to_solve = \"I had 10 cookies and ate 4. My friend gave me 2 more. How many cookies do I have now?\"\n",
        "final_answer = solve_word_problem(word_problem_to_solve)\n",
        "print(f\"\\nWord Problem: {word_problem_to_solve}\")\n",
        "print(f\"Final Answer: {final_answer}\")\n",
        "\n",
        "word_problem_to_solve_2 = \"The area of a rectangle is 25 square meters. If the width is 5 meters, what is the length?\"\n",
        "final_answer_2 = solve_word_problem(word_problem_to_solve_2)\n",
        "print(f\"\\nWord Problem: {word_problem_to_solve_2}\")\n",
        "print(f\"Final Answer: {final_answer_2}\")\n",
        "\n",
        "word_problem_to_solve_3 = \"What is the square root of 81?\"\n",
        "final_answer_3 = solve_word_problem(word_problem_to_solve_3)\n",
        "print(f\"\\nWord Problem: {word_problem_to_solve_3}\")\n",
        "print(f\"Final Answer: {final_answer_3}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Equation: 10 - 4 + 2\n",
            "Calculated Result: 8.0\n",
            "\n",
            "Word Problem: I had 10 cookies and ate 4. My friend gave me 2 more. How many cookies do I have now?\n",
            "Final Answer: You now have 8 cookies.\n",
            "Extracted Equation: 25/5\n",
            "Calculated Result: 5.0\n",
            "\n",
            "Word Problem: The area of a rectangle is 25 square meters. If the width is 5 meters, what is the length?\n",
            "Final Answer: The length of the rectangle is 5 meters.\n",
            "Extracted Equation: √81\n",
            "Error evaluating equation '√81': invalid character '√' (U+221A) (<string>, line 1)\n",
            "Calculated Result: nan\n",
            "\n",
            "Word Problem: What is the square root of 81?\n",
            "Final Answer: Could not calculate the result for the equation: √81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Cases\n",
        "\n",
        "To ensure our calculator agent works as expected, we'll test it with various examples. This section demonstrates how the complete agent workflow handles different types of mathematical questions, from simple arithmetic to word problems. Running these tests helps us verify that our agent can successfully parse queries, utilize its calculator tool, and provide accurate answers, proving that our agent is robust and reliable."
      ],
      "metadata": {
        "id": "ljXcGRTSU9Q7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad2a88be",
        "outputId": "dd2f531d-64a3-479f-8a9c-817b92535aad"
      },
      "source": [
        "# Test with a multiplication and addition problem\n",
        "word_problem_test_1 = \"If I buy 5 apples at 2 dollars each and 3 oranges at 1 dollar each, how much do I spend in total?\"\n",
        "final_answer_test_1 = solve_word_problem(word_problem_test_1)\n",
        "print(f\"\\nWord Problem: {word_problem_test_1}\")\n",
        "print(f\"Final Answer: {final_answer_test_1}\")\n",
        "\n",
        "# Test with a percentage problem\n",
        "word_problem_test_2 = \"What is 20% of 150?\"\n",
        "final_answer_test_2 = solve_word_problem(word_problem_test_2)\n",
        "print(f\"\\nWord Problem: {word_problem_test_2}\")\n",
        "print(f\"Final Answer: {final_answer_test_2}\")\n",
        "\n",
        "# Test with a problem that might require parentheses\n",
        "word_problem_test_3 = \"Calculate the result of adding 7 to 3 and then multiplying by 4.\"\n",
        "final_answer_test_3 = solve_word_problem(word_problem_test_3)\n",
        "print(f\"\\nWord Problem: {word_problem_test_3}\")\n",
        "print(f\"Final Answer: {final_answer_test_3}\")\n",
        "\n",
        "# Test with a division problem\n",
        "word_problem_test_4 = \"If 100 items are divided equally among 4 groups, how many items are in each group?\"\n",
        "final_answer_test_4 = solve_word_problem(word_problem_test_4)\n",
        "print(f\"\\nWord Problem: {word_problem_test_4}\")\n",
        "print(f\"Final Answer: {final_answer_test_4}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Equation: (5*2) + (3*1)\n",
            "Calculated Result: 13.0\n",
            "\n",
            "Word Problem: If I buy 5 apples at 2 dollars each and 3 oranges at 1 dollar each, how much do I spend in total?\n",
            "Final Answer: You spend a total of $13.\n",
            "Extracted Equation: 0.20*150\n",
            "Calculated Result: 30.0\n",
            "\n",
            "Word Problem: What is 20% of 150?\n",
            "Final Answer: 20% of 150 is 30.\n",
            "Extracted Equation: (7+3)*4\n",
            "Calculated Result: 40.0\n",
            "\n",
            "Word Problem: Calculate the result of adding 7 to 3 and then multiplying by 4.\n",
            "Final Answer: Adding 7 to 3 and then multiplying by 4 results in 40.\n",
            "Extracted Equation: 100/4\n",
            "Calculated Result: 25.0\n",
            "\n",
            "Word Problem: If 100 items are divided equally among 4 groups, how many items are in each group?\n",
            "Final Answer: Each group will have 25 items.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ypQtsXpTu0Jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Playaround**"
      ],
      "metadata": {
        "id": "Bqmk29I3zqLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_equation_from_word_problem(word_problem: str) -> str:\n",
        "    \"\"\"\n",
        "    Uses an LLM to extract the mathematical equation from a word problem.\n",
        "\n",
        "    Args:\n",
        "        word_problem: The math word problem as a string.\n",
        "\n",
        "    Returns:\n",
        "        A string representing the extracted mathematical equation, ready for a calculator.\n",
        "    \"\"\"\n",
        "    # Define the prompt for the LLM\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"Extract the mathematical equation from the word problem. Provide ONLY the equation itself, in a format suitable for direct input into a calculator or mathematical solver. For example, if the problem is 'What is 5 plus 3?', output '5 + 3'.\"),\n",
        "        (\"user\", \"Extract the equation from the following word problem: {word_problem}\")\n",
        "    ])\n",
        "\n",
        "    # Chain the prompt and the LLM\n",
        "    chain = prompt | base_llm\n",
        "\n",
        "    # Invoke the chain with the word problem\n",
        "    response = chain.invoke({\"word_problem\": word_problem})\n",
        "\n",
        "    # Return the extracted equation, ensuring no leading/trailing whitespace\n",
        "    return response.content.strip()\n",
        "\n",
        "# Example usage:\n",
        "word_problem = \"I have three apples and ate 1, how many do I have\"\n",
        "equation = get_equation_from_word_problem(word_problem)\n",
        "print(f\"Word Problem: {word_problem}\")\n",
        "print(f\"Extracted Equation: {equation}\")"
      ],
      "metadata": {
        "id": "i_NMNMqbz9OU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_"
      ],
      "metadata": {
        "id": "rRn2Nppx0SFl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}